{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwaxABBcrjqU/m0hwL0cBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chintan322/Machine-Learning/blob/master/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNYj7yCX4x7v"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "from array import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMZscqF85QMi"
      },
      "source": [
        "#Reading the Dataset using pandas\r\n",
        "ds = pd.read_csv('data.csv')\r\n",
        "\r\n",
        "cols = ds.columns\r\n",
        "no_of_attributes = cols.size\r\n",
        "len = int(ds.size/no_of_attributes);\r\n",
        "# print(len)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJuXKa_t5jou",
        "outputId": "06093403-d648-42a6-aac8-a51798023a73"
      },
      "source": [
        "# MinMax Scaling and saving data into data_scaled.csv file\r\n",
        "\r\n",
        "minmaxdiff = []\r\n",
        "# 0-min\r\n",
        "# 1-max\r\n",
        "# 2-diff = max-min\r\n",
        "# 3-mean\r\n",
        "\r\n",
        "for i in range(no_of_attributes):\r\n",
        "  min = ds[cols[i]].min();\r\n",
        "  max = ds[cols[i]].max();\r\n",
        "  diff = max-min;\r\n",
        "  mean = ds[cols[i]].mean();\r\n",
        "  minmaxdiff.insert(i,[min,max,diff,mean])\r\n",
        "\r\n",
        "# for r in minmaxdiff:\r\n",
        "#     for c in r:\r\n",
        "#         print(c,end = \" \")\r\n",
        "#     print()\r\n",
        "\r\n",
        "\r\n",
        "ds_copy = ds.copy()\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    # print(ds[cols[j]].loc[i]);\r\n",
        "    ds_copy[cols[j]].loc[i] = (ds_copy[cols[j]].loc[i] - minmaxdiff[j][0])/minmaxdiff[j][2]\r\n",
        "\r\n",
        "ds_copy.to_csv('data_scaled.csv',index=False,header=True)\r\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky46KX6i5-29",
        "outputId": "5899716f-666d-482a-83ab-3609f456b26c"
      },
      "source": [
        "#Creating random missingness in data and data_scaled dataset\r\n",
        "\r\n",
        "#Reading both dataset(datset without scaling , dataset with scaling)\r\n",
        "ds = pd.read_csv('data.csv')\r\n",
        "ds_scaled = pd.read_csv('data_scaled.csv')\r\n",
        "\r\n",
        "#Making copy for change in dataset\r\n",
        "ds_random = ds.copy()\r\n",
        "ds_scaled_random = ds_scaled.copy()\r\n",
        "\r\n",
        "#Choosing 50% instance randomly\r\n",
        "random_numbers = random.sample(range(len), int(len/2));\r\n",
        "\r\n",
        "random_feature_selection = []\r\n",
        "# random_feature_selection_scaled = []\r\n",
        "\r\n",
        "#Choosing 50% of 50% instance for injecting missingness feature wise\r\n",
        "\r\n",
        "for i in range(no_of_attributes):\r\n",
        "  rn = random.sample(random_numbers, int(len/4));\r\n",
        "  random_feature_selection.insert(i,rn)\r\n",
        "\r\n",
        "# rn1 = random.sample(random_numbers, int(len/4));\r\n",
        "# rn2 = random.sample(random_numbers, int(len/4));\r\n",
        "# rn3 = random.sample(random_numbers, int(len/4));\r\n",
        "# rn4 = random.sample(random_numbers, int(len/4));\r\n",
        "# rn5 = random.sample(random_numbers, int(len/4));\r\n",
        "# rn6 = random.sample(random_numbers, int(len/4));\r\n",
        "\r\n",
        "# for i in rn1:\r\n",
        "#   print(i);\r\n",
        "\r\n",
        "# random_numbers.sort()\r\n",
        "# len(random_numbers)\r\n",
        "\r\n",
        "# for operation of scaling\r\n",
        "# ds_copy = ds.copy()\r\n",
        "\r\n",
        "# for i in random_numbers:\r\n",
        "#   print(i);\r\n",
        "\r\n",
        "\r\n",
        "#Injecting missingness in dataset copies\r\n",
        "for i in range(len):\r\n",
        "  if random_numbers.count(i)==1:\r\n",
        "    for j in range(no_of_attributes):\r\n",
        "      if random_feature_selection[j].count(i)==1:\r\n",
        "        ds_random[cols[j]].loc[i]='NaN'\r\n",
        "        ds_scaled_random[cols[j]].loc[i]='NaN'\r\n",
        "\r\n",
        "# missingness in ds\r\n",
        "# ds_random\r\n",
        "# ds_scaled_random\r\n",
        "\r\n",
        "\r\n",
        "# for x in cols:\r\n",
        "#   print(x);\r\n",
        "\r\n",
        "# for x in range(len):\r\n",
        "#   print(df['Nature'].loc[x]);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-jDCRnyj_ZK",
        "outputId": "e253860c-2772-422b-9132-38cf1a57e632"
      },
      "source": [
        "# Imputing techniqu: Mean\r\n",
        "\r\n",
        "#Without scaling\r\n",
        "\r\n",
        "ds_random_before_imputing_mean = ds_random.copy()\r\n",
        "ds_random_after_imputing_mean = ds_random.copy()\r\n",
        "\r\n",
        "#Imputing missing value with Mean of that feature.\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    if ds_random[cols[j]].loc[i]=='NaN':\r\n",
        "      ds_random_after_imputing_mean[cols[j]].loc[i] = minmaxdiff[j][3]\r\n",
        "\r\n",
        "\r\n",
        "# Finding accuracy without scaling\r\n",
        "\r\n",
        "meanAccuracy = []\r\n",
        "NanFreq = []\r\n",
        "for j in range(no_of_attributes):\r\n",
        "  meanAccuracy.insert(j,0) \r\n",
        "  NanFreq.insert(j,0) \r\n",
        "\r\n",
        "\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    if ds_random_before_imputing_mean[cols[j]].loc[i]=='NaN':\r\n",
        "      meanAccuracy[j] += abs(ds_random_after_imputing_mean[cols[j]].loc[i] - ds[cols[j]].loc[i]) ** 2\r\n",
        "      NanFreq[j]+=1;\r\n",
        "print(\"MSE without scaling with imputation method: mean\")\r\n",
        "for j in range(no_of_attributes):\r\n",
        "  meanAccuracy[j] = meanAccuracy[j]/NanFreq[j];\r\n",
        "  print(meanAccuracy[j],end = \" \")\r\n",
        "  # print(meanAccuracy[j])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ds_random\r\n",
        "\r\n",
        "#With scaling data\r\n",
        "ds_scaled_random_before_imputing_mean = ds_scaled_random.copy()\r\n",
        "ds_scaled_random_after_imputing_mean = ds_scaled_random.copy()\r\n",
        "\r\n",
        "meanWithScaled = []\r\n",
        "\r\n",
        "for i in range(no_of_attributes):\r\n",
        "  mean = ds_scaled[cols[i]].mean();\r\n",
        "  meanWithScaled.insert(i,mean)\r\n",
        "\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    if ds_scaled_random[cols[j]].loc[i]=='NaN':\r\n",
        "      ds_scaled_random_after_imputing_mean[cols[j]].loc[i] = meanWithScaled[j]\r\n",
        "\r\n",
        "# Finding accuracy with scaling\r\n",
        "\r\n",
        "meanAccuracyS = []\r\n",
        "NanFreqS = []\r\n",
        "for j in range(no_of_attributes):\r\n",
        "  meanAccuracyS.insert(j,0) \r\n",
        "  NanFreqS.insert(j,0) \r\n",
        "\r\n",
        "\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    if ds_scaled_random_before_imputing_mean[cols[j]].loc[i]=='NaN':\r\n",
        "      meanAccuracyS[j] += abs(ds_scaled_random_after_imputing_mean[cols[j]].loc[i] - ds_scaled[cols[j]].loc[i]) ** 2\r\n",
        "      NanFreqS[j]+=1;\r\n",
        "\r\n",
        "print(\"\\nMSE with scaling with imputation method: mean\")\r\n",
        "for j in range(no_of_attributes):\r\n",
        "  meanAccuracyS[j] = meanAccuracyS[j]/NanFreqS[j];\r\n",
        "  print(meanAccuracyS[j],end = \" \")\r\n",
        "  # print(meanAccuracyS[j])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE without scaling with imputation method: mean\n",
            "41.33768535379814 1095.6285119667016 2692.6748178980224 1220.391925728408 1861.6019771071801 1176.3367748439123 \n",
            "MSE with scaling with imputation method: mean\n",
            "0.07814307250245399 0.04680372984607208 0.038055780681469024 0.051458590222989035 0.055588461199414164 0.047723509060972544 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgB8lmerm2x2"
      },
      "source": [
        "# Imputing techniqu: 1-NN\r\n",
        "\r\n",
        "#Without scaling\r\n",
        "\r\n",
        "ds_random_before_imputing_1NN = ds_random.copy()\r\n",
        "ds_random_after_imputing_1NN = ds_random.copy()\r\n",
        "\r\n",
        "def knn(i,j,k):\r\n",
        "  temp_array = [];\r\n",
        "  m=0;\r\n",
        "  while(m<len and m!=i):\r\n",
        "  # for m in range(len) and m != i:\r\n",
        "    temp = 0;\r\n",
        "    n=0;\r\n",
        "    while(n<no_of_attributes and n!=j):\r\n",
        "    # for n in range(no_of_attributes) and n != j:\r\n",
        "      temp += abs(ds_random_before_imputing_1NN[cols[n]].loc[m] - ds_random_before_imputing_1NN[cols[n]].loc[i]) ** 2;\r\n",
        "      n+=1;\r\n",
        "    temp_array.insert(m,[np.sqrt(temp),m]);\r\n",
        "  if k==1:\r\n",
        "    print(temp_array[0].min())\r\n",
        "    # xx = temp_array[0].min()\r\n",
        "    # print(xx)\r\n",
        "  m+=1;\r\n",
        "  # return ds_random_before_imputing_1NN[j].loc[index(temp_array.min())] \r\n",
        "  return 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for i in range(len):\r\n",
        "  for j in range(no_of_attributes):\r\n",
        "    if ds_random_before_imputing_1NN[cols[j]].loc[i]=='NaN':\r\n",
        "      ds_random_after_imputing_1NN[cols[j]].loc[i] = knn(i,j,1)\r\n",
        "      \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}